{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c555bfa8-b98e-4a64-93ef-a74636b95a9f",
    "_uuid": "7f4433826f377d7075029346549f44864b87eb4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import moment, kurtosis, skew\n",
    "import pywt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff9641d7-ecb4-417e-acfe-32de856ee7c7",
    "_uuid": "3ce419710a34b287ae5459cf06e63f39fa9e3c89",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction - Local Binary Pattern\n",
    "def lbp_feature_extraction(im, n_points, radius, method):\n",
    "    #im_gray = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)\n",
    "    lbp = local_binary_pattern(im[:,:,0], n_points, radius, method)\n",
    "    # Features returned are the hisogram of resulting data from lbp algorithm\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, radius + 2))\n",
    "    \n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "665bf19f-1e2b-47cd-a0a1-cc673808e8cf",
    "_uuid": "e2a12bdf79094486f5f33440f02f52a5535bb3c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction - Denoise Wavelets\n",
    "def den_wavelets(noise):    \n",
    "    resp = []\n",
    "    n_moments = 9\n",
    "    for i in range(np.shape(noise)[2]):\n",
    "        coeffs = pywt.dwt2(noise[:,:,i], 'haar')\n",
    "        cA, (cH, cV, cD) = coeffs\n",
    "        for j in range(1,n_moments+1):\n",
    "            resp.append(moment(cH.ravel(), moment=j))\n",
    "            resp.append(moment(cV.ravel(), moment=j))\n",
    "            resp.append(moment(cD.ravel(), moment=j))\n",
    "        resp.append(kurtosis(cH.ravel()))\n",
    "        resp.append(kurtosis(cV.ravel()))\n",
    "        resp.append(kurtosis(cD.ravel()))\n",
    "        resp.append(skew(cH.ravel()))\n",
    "        resp.append(skew(cV.ravel()))\n",
    "        resp.append(skew(cD.ravel()))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34bb4822-de3c-4bc3-8146-b3ab7e5bd7d7",
    "_uuid": "412ef5ce1efc36c21c6f82dc6374758b98b3d14c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_center_image(im, rows, columns):\n",
    "    im = rgb_image\n",
    "    h_mean = np.shape(im)[0]//2\n",
    "    l_mean = np.shape(im)[1]//2\n",
    "    rows_inc = rows//2\n",
    "    columns_inc = columns//2\n",
    "    im = im[h_mean-rows_inc:h_mean+rows_inc, l_mean-columns_inc:l_mean+columns_inc,:]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "426883ac-5b59-4cf3-8216-adaefaeb559a",
    "_uuid": "b454d83e9861300d166c4b594e36a23f17ece0a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''seg = train[train['camera'] == cameras[1]]\n",
    "seg = seg.reset_index()\n",
    "path_im = train_path / seg.at[0, 'camera'] / seg.at[120, 'fname']\n",
    "bgr_image = cv2.imread(str(path_im))\n",
    "rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "#im = cv2.resize(rgb_image, (128, 128))\n",
    "im = rgb_image\n",
    "\n",
    "print(np.shape(im))\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.figure()\n",
    "start = time.time()\n",
    "plt.imshow(crop_center_image(im, 512, 512))\n",
    "end = time.time()\n",
    "print('%f'%(end-start))\n",
    "\n",
    "#a = den_wavelets(im)\n",
    "#print(np.shape(a))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c9406230-69f6-4b4f-9125-4ec5067c88ea",
    "_uuid": "e2f22fbd2af0fad38afdd29d1e5915088a15c9d6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_kaggle = True\n",
    "# Generating train and test path\n",
    "if is_kaggle:\n",
    "    input_path = Path('../input')\n",
    "else:\n",
    "    input_path = Path('../input')\n",
    "train_path = input_path / 'train'\n",
    "test_path = input_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9cfc24c9-bd9b-479e-877d-aeb906fb8f73",
    "_uuid": "145cca5f8286bbbbe8a8617c818406f0e4a290b2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Listing all directories in trainning path\n",
    "cameras = os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b9c8199-f18d-4022-9382-e169811c5155",
    "_uuid": "09608fd0ee7f21854981e1a184de9532340be117",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining size of trainning\n",
    "size_train = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22c7e87e-9fde-40ef-a92d-a16bca32cf8c",
    "_uuid": "7b8f7888f687bd04c34d5daafca4c22009671c77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating DataFrame of images and labes in the trainning and validation dataset\n",
    "train_images = []\n",
    "n_pictures = []\n",
    "\n",
    "for camera in cameras:\n",
    "    pic = len(os.listdir(train_path / camera))\n",
    "    n_pictures.append(pic)\n",
    "    for fname in sorted(os.listdir(train_path / camera)):\n",
    "            train_images.append((camera, fname))\n",
    "train = pd.DataFrame(train_images, columns=['camera', 'fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "620c9e93-c615-444c-a564-39c603e25545",
    "_uuid": "59e4c960dd5cba6122eaa715accf1374df90b0e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating DataFrame of images and labes in the testing dataset\n",
    "test_images = []\n",
    "for fname in sorted(os.listdir(test_path)):\n",
    "    test_images.append(fname)\n",
    "test = pd.DataFrame(test_images, columns=['fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae01e175-744a-4a78-b169-892cf091627f",
    "_uuid": "37b04a8a4415f69631b53709c44434711560261e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Procedure to mount feature vectors of trainning and validation\n",
    "train_lbp = []\n",
    "train_wav = []\n",
    "valid_lbp = []\n",
    "valid_wav = []\n",
    "train_target = []\n",
    "valid_target = []\n",
    "\n",
    "im_mean_vec = []\n",
    "im_mean = 0\n",
    "\n",
    "j = 0\n",
    "\n",
    "start = time.time()\n",
    "for camera in cameras:\n",
    "    print(\"Feature extraction: %s\"%(camera))\n",
    "    for i in range(n_pictures[j]):\n",
    "        print(\"Example %i\"%i, end = '\\r')\n",
    "        seg = train[train['camera'] == camera]\n",
    "        seg = seg.reset_index()\n",
    "        path_im = train_path / seg.at[i, 'camera'] / seg.at[i, 'fname']\n",
    "        bgr_image = cv2.imread(str(path_im))\n",
    "        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "        #im = rgb_image\n",
    "        im = crop_center_image(rgb_image, 512, 512)\n",
    "        im_clean = denoise_wavelet(im, multichannel=True)\n",
    "        noise = im - im_clean\n",
    "        #im = cv2.resize(rgb_image, (512, 512))\n",
    "        if i < 220:\n",
    "            train_wav.append(den_wavelets(noise))\n",
    "            train_lbp.append(lbp_feature_extraction(noise, 24, 8, 'uniform'))\n",
    "            train_target.append(seg.at[i, 'camera'])\n",
    "        else:\n",
    "            valid_wav.append(den_wavelets(noise))\n",
    "            valid_lbp.append(lbp_feature_extraction(noise, 24, 8, 'uniform'))\n",
    "            valid_target.append(seg.at[i, 'camera'])\n",
    "        \n",
    "        im_mean += noise\n",
    "    im_mean_vec.append(im_mean/(i+1))\n",
    "    im_mean = 0\n",
    "    \n",
    "    j += 1\n",
    "    print(\"Extraction finished!\\n\")\n",
    "end = time.time()\n",
    "\n",
    "print('The time elapsed to extract all features was: %.2f min'%((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64423c35-ed6c-4ac9-9fa5-789248ad81c6",
    "_uuid": "ada2e2bdc7936d83ec466163a43034bc222477eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_vec = []\n",
    "valid_vec = []\n",
    "        \n",
    "for camera in cameras:\n",
    "    print(\"Feature extraction: %s\"%(camera))\n",
    "    for i in range(275):\n",
    "        print(\"Example %i\"%i, end = '\\r')\n",
    "        seg = train[train['camera'] == camera]\n",
    "        seg = seg.reset_index()\n",
    "        path_im = train_path / seg.at[i, 'camera'] / seg.at[i, 'fname']\n",
    "        bgr_image = cv2.imread(str(path_im))\n",
    "        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "        #im = rgb_image\n",
    "        im = crop_center_image(rgb_image, 512, 512)\n",
    "        \n",
    "        im_clean = denoise_wavelet(im, multichannel=True)\n",
    "        noise = im - im_clean\n",
    "        \n",
    "        features_sing = []\n",
    "        \n",
    "        for j in range(3):\n",
    "            aux = np.corrcoef(noise[:,:,j].ravel(),np.array(im_mean_vec)[:,:,:,j].reshape(10,-1))\n",
    "            features_sing = np.concatenate((features_sing, aux[:,0]))  \n",
    "        if i < 220:\n",
    "            features_vec.append(features_sing)\n",
    "        else:\n",
    "            valid_vec.append(features_sing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d25a1c82-50e8-4e0d-a9ad-457889ab5bb6",
    "_uuid": "5c4cccca9f1ea517b12fa9006cef06be3597f377",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_wav = np.array(train_wav)\n",
    "train_wav = train_wav.reshape(np.shape(train_wav)[0],-1)\n",
    "\n",
    "valid_wav = np.array(valid_wav)\n",
    "valid_wav = valid_wav.reshape(np.shape(valid_wav)[0],-1)\n",
    "\n",
    "final_feat = np.concatenate((train_wav, features_vec, train_lbp), axis=1)\n",
    "final_valid = np.concatenate((valid_wav, valid_vec, valid_lbp), axis=1)\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "final_feat = scaler_final.fit_transform(final_feat)\n",
    "final_valid = scaler_final.transform(final_valid)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav = scaler.fit_transform(train_wav)\n",
    "valid_wav = scaler.transform(valid_wav)\n",
    "\n",
    "scaler_lbp = StandardScaler()\n",
    "train_lbp = scaler_lbp.fit_transform(train_lbp)\n",
    "valid_lbp = scaler_lbp.transform(valid_lbp)\n",
    "\n",
    "scaler_corr = StandardScaler()\n",
    "features_vec = scaler_corr.fit_transform(features_vec)\n",
    "valid_vec = scaler_corr.transform(valid_vec)\n",
    "\n",
    "#Predicting using logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "print('Logistic Regression\\nTrainning')\n",
    "print('LBP - Score: %.2f'%(logistic.fit(train_lbp, train_target).score(train_lbp, train_target)))\n",
    "print('WAV - Score: %.2f'%(logistic.fit(train_wav, train_target).score(train_wav, train_target)))\n",
    "print('CORR - Score: %.2f'%(logistic.fit(features_vec, train_target).score(features_vec, train_target)))\n",
    "print('ALL - Score: %.2f'%(logistic.fit(final_feat, train_target).score(final_feat, train_target)))\n",
    "print('Validation')\n",
    "print('LBP - Score: %.2f'%(logistic.fit(train_lbp, train_target).score(valid_lbp, valid_target)))\n",
    "print('WAV - Score: %.2f'%(logistic.fit(train_wav, train_target).score(valid_wav, valid_target)))\n",
    "print('CORR - Score: %.2f'%(logistic.fit(features_vec, train_target).score(valid_vec, valid_target)))\n",
    "print('ALL - Score: %.2f\\n'%(logistic.fit(final_feat, train_target).score(final_valid, valid_target)))\n",
    "\n",
    "# Predicting using KNN\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "print('K-Nearest Neighbors\\nTrainning')\n",
    "print('LBP - Score: %.2f'%(knn.fit(train_lbp, train_target).score(train_lbp, train_target)))\n",
    "print('WAV - Score: %.2f'%(knn.fit(train_wav, train_target).score(train_wav, train_target)))\n",
    "print('CORR - Score: %.2f'%(knn.fit(features_vec, train_target).score(features_vec, train_target)))\n",
    "print('ALL - Score: %.2f'%(knn.fit(final_feat, train_target).score(final_feat, train_target)))\n",
    "print('Validation')\n",
    "print('LBP - Score: %.2f'%(knn.fit(train_lbp, train_target).score(valid_lbp, valid_target)))\n",
    "print('WAV - Score: %.2f'%(knn.fit(train_wav, train_target).score(valid_wav, valid_target)))\n",
    "print('CORR - Score: %.2f'%(knn.fit(features_vec, train_target).score(valid_vec, valid_target)))\n",
    "print('ALL - Score: %.2f\\n'%(knn.fit(final_feat, train_target).score(final_valid, valid_target)))\n",
    "\n",
    "# Predicting using logistic regression\n",
    "mlp = MLPClassifier(activation = 'relu')\n",
    "print('Multilayer Perceptron\\nTrainning')\n",
    "print('LBP - Score: %.2f'%(mlp.fit(train_lbp, train_target).score(train_lbp, train_target)))\n",
    "print('WAV - Score: %.2f'%(mlp.fit(train_wav, train_target).score(train_wav, train_target)))\n",
    "print('CORR - Score: %.2f'%(mlp.fit(features_vec, train_target).score(features_vec, train_target)))\n",
    "print('ALL - Score: %.2f'%(mlp.fit(final_feat, train_target).score(final_feat, train_target)))\n",
    "print('Validation')\n",
    "print('LBP - Score: %.2f'%(mlp.fit(train_lbp, train_target).score(valid_lbp, valid_target)))\n",
    "print('WAV - Score: %.2f'%(mlp.fit(train_wav, train_target).score(valid_wav, valid_target)))\n",
    "print('CORR - Score: %.2f'%(mlp.fit(features_vec, train_target).score(valid_vec, valid_target)))\n",
    "print('ALL - Score: %.2f'%(mlp.fit(final_feat, train_target).score(final_valid, valid_target)))\n",
    "\n",
    "print(np.shape(train_lbp), np.shape(train_wav))\n",
    "print(np.shape(np.concatenate((train_lbp, train_wav), axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29c04458-655d-4fb5-9976-30c22205c5cf",
    "_uuid": "1a705c35c3ceaf4177dff3e2dcabf90e73f8fc23",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp.fit(final_feat, train_target)\n",
    "\n",
    "submit = []\n",
    "\n",
    "print('fname,camera')\n",
    "for i in range(np.shape(test)[0]):\n",
    "    print('%i'%i, end ='\\r')\n",
    "    path_im = test_path /  test.at[i, 'fname']\n",
    "    bgr_image = cv2.imread(str(path_im))\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)   \n",
    "    im_clean = denoise_wavelet(rgb_image, multichannel=True)\n",
    "    noise = rgb_image - im_clean\n",
    "    test_wav = den_wavelets(noise)\n",
    "    test_wav = np.array(test_wav).reshape(1,-1)\n",
    "    #test_wav = scaler.transform(test_wav)\n",
    "    #test_wav = np.array(test_wav)\n",
    "    #test_wav = test_wav.reshape(np.shape(test_wav)[0],-1)\n",
    "    \n",
    "    test_lbp = lbp_feature_extraction(noise, 24, 8, 'uniform')\n",
    "    \n",
    "    test_sing = []\n",
    "    \n",
    "    for j in range(3):\n",
    "            aux = np.corrcoef(noise[:,:,j].ravel(),np.array(im_mean_vec)[:,:,:,j].reshape(10,-1))\n",
    "            test_sing = np.concatenate((test_sing, aux[:,0])) \n",
    "\n",
    "\n",
    "    test_feat = np.concatenate((test_wav[0], test_sing, test_lbp), axis=0)\n",
    "\n",
    "    test_feat = scaler_final.transform(test_feat.reshape(1,-1))\n",
    "\n",
    "    pred = mlp.predict(test_feat)\n",
    "    \n",
    "    submit.append([test.at[i, 'fname'], pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca06eb86-b31f-4508-9ee8-c4192645d262",
    "_uuid": "bda5ea599dd9dd94d143e04665669b58cf85a13d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_pd = pd.DataFrame(submit, columns=['fname', 'camera'])\n",
    "\n",
    "print(submit_pd)\n",
    "\n",
    "submit_pd.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
