{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2\n",
    "from imutils import paths\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from scipy.stats import moment\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_alter(image):\n",
    "    i = random.randint(1,8)\n",
    "    if i == 1:\n",
    "        return (0, image)\n",
    "    if i == 2:\n",
    "        cv2.imwrite('image.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 70])\n",
    "        return (1,cv2.imread('image.jpg'))\n",
    "    if i == 3:\n",
    "        cv2.imwrite('image.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "        return (1,cv2.imread('image.jpg'))\n",
    "    if i == 4:\n",
    "        return (1,cv2.resize(image,None,fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC))\n",
    "    if i == 5:\n",
    "        return (1,cv2.resize(image,None,fx=0.8, fy=0.8, interpolation = cv2.INTER_CUBIC))\n",
    "    if i == 6:\n",
    "        return (1,cv2.resize(image,None,fx=1.5, fy=1.5, interpolation = cv2.INTER_CUBIC))\n",
    "    if i == 7:\n",
    "        return (1,cv2.resize(image,None,fx=2.0, fy=2.0, interpolation = cv2.INTER_CUBIC))\n",
    "    if i == 8:\n",
    "        return (1,adjust_gamma(image,gamma=0.8))\n",
    "    if i == 9:\n",
    "        return (1,adjust_gamma(image,gamma=1.2))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winVar(img, wlen):\n",
    "  wmean, wsqrmean = (cv2.boxFilter(x, -1, (wlen, wlen), borderType=cv2.BORDER_REFLECT) for x in (img, img*img))\n",
    "  return wsqrmean - wmean*wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denoise_band(X, wavelet, levels, alpha):\n",
    "#     from var_est import variance\n",
    "\n",
    "    if alpha is None:\n",
    "        alpha = 2\n",
    "\n",
    "    decomp = pywt.wavedec2(X, wavelet, level=levels)\n",
    "    for i, all_coeff in enumerate(decomp[1:]):\n",
    "        minvar = np.empty(all_coeff[0].shape, dtype=float)\n",
    "        minvar.fill(np.inf)\n",
    "        # Handle horizontal, vertical and diagonal coefficients\n",
    "        for coeff in all_coeff:\n",
    "            for win_size in (3, 5, 7, 9):\n",
    "                var = winVar(coeff, win_size)\n",
    "                mask = (var < minvar)\n",
    "                minvar[mask] = var[mask]\n",
    "\n",
    "            # Wiener estimator\n",
    "            coeff *= (minvar / (minvar + alpha))\n",
    "\n",
    "    rec = pywt.waverec2(decomp, wavelet)\n",
    "    rows, cols = X.shape\n",
    "    if X.shape != rec.shape:\n",
    "        rows_mod = rows % 2\n",
    "        cols_mod = cols % 2\n",
    "        return rec[rows_mod:, cols_mod:]\n",
    "    else:\n",
    "        return rec\n",
    "\n",
    "def dwt_noise(X, wavelet='db8', levels=4, alpha=2):\n",
    "    \"\"\"Denoise an image using the Discrete Wavelet Transform.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of uint8\n",
    "        Image to denoise.\n",
    "    wavelet : str\n",
    "        Wavelet family to use.  See `supreme.lib.pywt.wavelist()` for a\n",
    "        complete list.\n",
    "    levels : int\n",
    "        Number of levels to use in the decomposition.\n",
    "    alpha : float\n",
    "        Parameter used to tweak the Wiener estimator.  A larger\n",
    "        value of `alpha` results in a smoother output.\n",
    "    Returns\n",
    "    -------\n",
    "    Y : ndarray of float64\n",
    "        Denoised image.\n",
    "    Notes\n",
    "    -----\n",
    "    Implemented according to the overview of [2]_ given in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. Fridrich, \"Digital Image Forensics,\" IEEE Signal Processing\n",
    "           Magazine, vol. 26, 2009, pp. 26-37.\n",
    "    .. [2] M. Mihcak, I. Kozintsev, K. Ramchandran, and P. Moulin,\n",
    "           \"Low-complexity image denoising based on statistical\n",
    "           modeling of wavelet coefficients,\" IEEE Signal Processing\n",
    "           Letters, vol. 6, 1999, pp. 300-303.\n",
    "    \"\"\"\n",
    "    noise = np.zeros(X.shape, dtype=float)\n",
    "    if X.ndim == 3:\n",
    "        bands = X.shape[2]\n",
    "\n",
    "        for b in range(bands):\n",
    "            noise[:, :, b] = X[:, :, b] - _denoise_band(X[..., b], wavelet, levels, alpha)\n",
    "            mean = noise[:, :, b].mean()\n",
    "            noise[:, :, b] = list(map(lambda x: x - mean, noise[:, :, b]))\n",
    "#     else:\n",
    "#         out[:] = _denoise_band(X, wavelet, levels, alpha)\n",
    "#         MIN = out.min()\n",
    "#         MAX = out.max()\n",
    "#         out = list(map(lambda x: (x-MIN)*255/(MAX - MIN), out))\n",
    "    noise[:, :, 0] = 0.3*noise[:,:,0]\n",
    "    noise[:, :, 1] = 0.6*noise[:,:,1]\n",
    "    noise[:, :, 2] = 0.1*noise[:,:,2]\n",
    "\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_noise(noise, wavelet='db8'):\n",
    "    bands = noise.shape[2]\n",
    "    features = []\n",
    "    for b in range(bands):\n",
    "        decomp = pywt.wavedec2(noise[:,:,b], wavelet, level=1)\n",
    "        for i in range(3):\n",
    "            for j in range(1,10):\n",
    "                features.append(moment(decomp[1][i].reshape(-1,1),j)[0])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBP(image,numPoints=24, radius=3):\n",
    "    eps=1e-7\n",
    "    lbp = local_binary_pattern(image, numPoints, radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), \\\n",
    "                                bins=np.arange(0, numPoints + 3), \\\n",
    "                                range=(0, numPoints + 2))\n",
    " \n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    " \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2num(vec, labels):\n",
    "    df = pd.DataFrame(vec,columns=['label'])\n",
    "    label_dict = {}\n",
    "    for i,label in enumerate(labels):\n",
    "        df.loc[df.label==label] = i\n",
    "        label_dict[str(i)] = label\n",
    "    return df.label.values, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2label(label_num,label_dict):\n",
    "    label_num = label_num.astype(str)\n",
    "    for num in np.unique(label_num):\n",
    "        label_num[label_num==num] = label_dict[num]\n",
    "    return label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted\n",
      "Elapsed time: 245 minutes and 42 seconds\n"
     ]
    }
   ],
   "source": [
    "# progress = FloatProgress(min=0, max=len(list(paths.list_images('data/train'))))\n",
    "# display(progress)\n",
    "# progress.value = 0\n",
    "tic = time.time()\n",
    "labels = []\n",
    "features_lbp = []\n",
    "features_noise = []\n",
    "noise_mean = {}\n",
    "for im in paths.list_images('data/train'):\n",
    "    image = cv2.imread(im)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    c1 = int(image.shape[0]/2)\n",
    "    c2 = int(image.shape[1]/2)\n",
    "    crop = image[c1-256:c1+256,c2-256:c2+256]\n",
    "    \n",
    "    noise = dwt_noise(crop)\n",
    "#     for i in range(3):\n",
    "#         MAX = noise[:,:,i].max()\n",
    "#         MIN = noise[:,:,i].min()\n",
    "#         f = np.vectorize(lambda x: (x-MIN)*255/(MAX-MIN))\n",
    "#         noise[:,:,i] = f(noise[:,:,i])\n",
    "#     noise = noise.astype(np.uint8)\n",
    "        \n",
    "    feats = features_from_noise(noise)\n",
    "    features_noise.append(feats)\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    hist = LBP(gray)\n",
    "    features_lbp.append(hist)\n",
    "    \n",
    "    if im.split(\"/\")[-2] in noise_mean.keys():\n",
    "        noise_mean[im.split(\"/\")[-2]] += noise/275\n",
    "    else:\n",
    "        noise_mean[im.split(\"/\")[-2]] = noise/275\n",
    "\n",
    "    labels.append(im.split(\"/\")[-2])\n",
    "\n",
    "toc = time.time()\n",
    "print('Features extracted')\n",
    "print('Elapsed time: %d minutes and %d seconds' % (int((toc-tic)/60),int((toc-tic)%60)))\n",
    "#     progress.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manip.tif'"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname[0].split('_')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_mean_vec = []\n",
    "for key, value in noise_mean.items():\n",
    "    noise_mean_vec.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted\n",
      "Elapsed time: 12 minutes and 42 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "features_corr = []\n",
    "for im in paths.list_images('data/train'):\n",
    "    image = cv2.imread(im)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    c1 = int(image.shape[0]/2)\n",
    "    c2 = int(image.shape[1]/2)\n",
    "    crop = image[c1-256:c1+256,c2-256:c2+256]\n",
    "    feats = []\n",
    "#     for i in range(3):\n",
    "    aux = np.corrcoef(crop.ravel(),np.array(noise_mean_vec).reshape(10,-1))[0,1:]\n",
    "#         feats = np.concatenate((feats,aux[0,1:]))\n",
    "    features_corr.append(aux)\n",
    "toc = time.time()\n",
    "print('Features extracted')\n",
    "print('Elapsed time: %d minutes and %d seconds' % (int((toc-tic)/60),int((toc-tic)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_num, label_dict = label2num(labels,np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'HTC-1-M7',\n",
       " '1': 'LG-Nexus-5x',\n",
       " '2': 'Motorola-Droid-Maxx',\n",
       " '3': 'Motorola-Nexus-6',\n",
       " '4': 'Motorola-X',\n",
       " '5': 'Samsung-Galaxy-Note3',\n",
       " '6': 'Samsung-Galaxy-S4',\n",
       " '7': 'Sony-NEX-7',\n",
       " '8': 'iPhone-4s',\n",
       " '9': 'iPhone-6'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted\n",
      "Elapsed time: 17 minutes and 31 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "fname = []\n",
    "features_lbp_test = []\n",
    "features_noise_test = []\n",
    "features_corr_test = []\n",
    "for im in paths.list_images('data/test'):\n",
    "    image = cv2.imread(im)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    noise = dwt_noise(image)\n",
    "#     for i in range(3):\n",
    "#         MAX = noise[:,:,i].max()\n",
    "#         MIN = noise[:,:,i].min()\n",
    "#         f = np.vectorize(lambda x: (x-MIN)*255/(MAX-MIN))\n",
    "#         noise[:,:,i] = f(noise[:,:,i])\n",
    "#     noise = noise.astype(np.uint8)\n",
    "    \n",
    "    feats = features_from_noise(noise)\n",
    "    features_noise_test.append(feats)\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    hist = LBP(gray)\n",
    "    features_lbp_test.append(hist)\n",
    "    \n",
    "#     feats = []\n",
    "#     for i in range(3):\n",
    "    aux = np.corrcoef(image[:,:,i].ravel(),np.array(noise_mean_vec)[:,:,:,i].reshape(10,-1))[0,1:]\n",
    "#         feats = np.concatenate((feats,aux[0,1:]))\n",
    "    features_corr_test.append(aux)\n",
    "    \n",
    "    fname.append(im.split(\"/\")[-1])\n",
    "\n",
    "toc = time.time()\n",
    "print('Features extracted')\n",
    "print('Elapsed time: %d minutes and %d seconds' % (int((toc-tic)/60),int((toc-tic)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# all_feats_train = np.concatenate((np.array(features_lbp),np.array(features_noise)),axis=1)\n",
    "#all_feats_train = np.concatenate((all_feats_train,np.array(features_corr)),axis=1)\n",
    "all_feats_train = np.array(features_lbp)\n",
    "all_feats_train = sc.fit_transform(all_feats_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feats_test = np.concatenate((np.array(features_lbp_test),np.array(features_noise_test)),axis=1)\n",
    "#all_feats_test = np.concatenate((all_feats_test,np.array(features_corr_test)),axis=1)\n",
    "all_feats_test = np.array(features_lbp_test)\n",
    "all_feats_test = sc.transform(all_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "x_train = lda.fit_transform(all_feats_train,labels_num)\n",
    "x_test = lda.transform(all_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "x_train = pca.fit_transform(all_feats_train)\n",
    "x_test = pca.transform(all_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.explained_variance_ratio_[:9].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0 minutes and 16 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42,n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),alpha=0.5,solver='sgd', learning_rate_init=0.1,max_iter=500,random_state=42)\n",
    "models = [lr, knn, mlp]\n",
    "kf = KFold(n_splits=10,shuffle=True,random_state=42)\n",
    "scores_train = np.zeros((10,len(models)))\n",
    "scores_test = np.zeros((10,len(models)))\n",
    "x_train_ensemble = np.zeros((x_train.shape[0],len(models)))\n",
    "i = 0\n",
    "tic = time.time()\n",
    "for train_index, test_index in kf.split(labels_num):\n",
    "    X_train, X_test = [x_train[i] for i in train_index], [x_train[i] for i in test_index]\n",
    "    y_train, y_test = labels_num[train_index], labels_num[test_index]\n",
    "    for j,model in enumerate(models):\n",
    "        model.fit(X_train,y_train)\n",
    "        x_train_ensemble[test_index,j] = model.predict(X_test)\n",
    "        scores_train[i,j] = model.score(X_train,y_train)\n",
    "        scores_test[i,j] = model.score(X_test,y_test)\n",
    "        \n",
    "    i+=1\n",
    "toc = time.time()\n",
    "print('Elapsed time: %d minutes and %d seconds' % (int((toc-tic)/60),int((toc-tic)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "Accuracy score: 0.86\n",
      "-------------------------------------------------------------------------------\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Accuracy score: 0.91\n",
      "-------------------------------------------------------------------------------\n",
      "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "Accuracy score: 0.89\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, labels_num, test_size=0.2, random_state=42)\n",
    "lr = LogisticRegression(random_state=42,n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),alpha=0.5,solver='sgd', learning_rate_init=0.1,max_iter=500,random_state=42)\n",
    "models = [lr, knn, mlp]\n",
    "y_pred = np.zeros((X_test.shape[0],3))\n",
    "for j,model in enumerate(models):\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred[:,j] = model.predict(X_test)\n",
    "        print(model.__class__)\n",
    "        print('Accuracy score: %.2f' % (accuracy_score(y_pred[:,j],y_test)))\n",
    "        print('-------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8356363636363637, 0.8974545454545455, 0.8974545454545453]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[scores_test[:,i].mean() for i in range(scores_test.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0  2  0  4  0  0  2  0  0]\n",
      " [ 0 59  0  0  2  0  1  0  0  1]\n",
      " [ 4  0 52  0  0  0  2  1  2  3]\n",
      " [ 0  0  0 42  0  0  2  0  4  3]\n",
      " [ 2  1  1  0 44  2  1  1  0  1]\n",
      " [ 0  0  2  0  3 50  0  1  1  1]\n",
      " [ 1  1  0  1  0  3 49  2  0  1]\n",
      " [ 0  1  4  0  0  0  2 47  0  0]\n",
      " [ 0  0  2  0  2  0  0  0 43  0]\n",
      " [ 2  0  0  1  0  3  1  0  1 46]]\n",
      "\n",
      "[[43  0  1  0  2  0  0  2  0  0]\n",
      " [ 0 60  0  1  1  0  0  0  0  1]\n",
      " [ 2  0 58  1  0  1  0  1  1  0]\n",
      " [ 1  0  0 47  0  1  0  0  1  1]\n",
      " [ 1  1  2  0 44  1  0  2  1  1]\n",
      " [ 0  0  2  0  2 53  0  0  0  1]\n",
      " [ 1  2  2  1  0  3 48  1  0  0]\n",
      " [ 0  0  3  0  0  0  0 51  0  0]\n",
      " [ 0  0  2  1  0  0  0  0 44  0]\n",
      " [ 0  1  0  0  0  0  0  0  2 51]]\n",
      "\n",
      "[[41  0  3  0  2  0  0  2  0  0]\n",
      " [ 1 59  0  0  1  0  1  0  0  1]\n",
      " [ 2  0 53  2  0  0  1  2  2  2]\n",
      " [ 1  0  0 47  1  0  0  0  1  1]\n",
      " [ 2  1  0  1 44  1  1  1  1  1]\n",
      " [ 0  0  2  1  3 50  0  0  1  1]\n",
      " [ 1  2  1  1  0  3 49  1  0  0]\n",
      " [ 0  0  2  0  0  0  0 52  0  0]\n",
      " [ 0  0  1  2  0  0  0  0 43  1]\n",
      " [ 0  1  0  0  0  0  0  0  1 52]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(confusion_matrix(y_test,y_pred[:,i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "x_test_ensemble = np.zeros((x_test.shape[0],len(models)))\n",
    "for j,model in enumerate(models):\n",
    "        model.fit(x_train,labels_num)\n",
    "        x_test_ensemble[:,j] = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(x):\n",
    "    rows = x.shape[0]\n",
    "    y = np.zeros((rows,))\n",
    "    for i in range(rows):\n",
    "        if np.unique(x[i,:]).shape[0] == 3:\n",
    "            y[i] = x[i,2]\n",
    "        else:\n",
    "            y[i] = mode(x[i,:])[0][0]\n",
    "    return y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_mode(x_test_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train,labels_num)\n",
    "y = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = num2label(y,label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['fname'] = fname\n",
    "result['camera'] = camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('results/result_model1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
